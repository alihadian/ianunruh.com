---
layout: post
title: "The State of Highly-Available Syslog"
date: 2014-08-02 18:41:00
comments: true
---

So, you've played with Logstash or one of the multitude of other log aggregation tools (Flume, Fluentd, rsyslog, syslog-ng, etc.) Now you want to start shipping logs from your networking and legacy devices to your logging infrastructure. For most situations, you can just turn on a syslog receiver on your indexer and point your shipper at it. However, when you have to perform maintenance or your indexer experiences downtime, log loss may occur.

There are a lot of different situations at hand that can affect the solution you use for minimizing or eliminating log loss.

- The shipper uses a reliable protocol like TCP
- The shipper uses an unreliable protocol like UDP
- The shipper can fanout to multiple receivers
- The shipper has receiver failover support
- The receiver can journal incoming events to disk
- The receiver can perform de-duplication of events

There are a few things I've noticed in regards to the current landscape of networking devices and logging.

- Network devices generally support both TCP and UDP syslog
- For the most part, network devices only support one receiver (except for high-end devices, like the Cisco ASA series)
- I don't know of any network devices that support receiver failover

When it comes to journaling, some receivers come really close.

- The commercial version of syslog-ng [can journal](http://www.balabit.com/sites/default/files/documents/syslog-ng-pe-4.0-guides/en/syslog-ng-pe-v4.0-guide-admin-en/html/concepts_logstore_journal.html) enough to protect against itself crashing, but not the OS crashing.
- Flume supports [durable channels](https://cwiki.apache.org/confluence/display/FLUME/Getting+Started), but it is unclear if the sources themselves are durable.
- Heka definitely does not journal at the time of this writing, as evidenced by conversations I've had in the Heka IRC channel.
- Fluentd decided that the tradeoff between durability and speed [should be entirely in favor of speed](http://docs.fluentd.org/articles/high-availability). They decided to use at-most-once delivery semantics.
- Logstash makes no claims about durability that I could find
- Graylog2 makes no claims about durability that I could find

Given all of this, it appears that there is no easy way to perform exactly-once delivery. We have to settle for one of the following solutions.

- At-most-once delivery - Have two receivers in active/standby mode with a shared VIP
- At-least-once delivery - Have two receivers in active/active mode (with de-duplication it can become exactly-once delivery)

### Active/standby

If your goal is to just minimize log loss, then you can stand up two instances of your log receiver of choice and use keepalived. Use this with TCP or UDP syslog, depending on your network reliability.

![VIP failover with keepalived](/images/ha-syslog.png)

On each indexer, it's trivial to setup keepalived. If you're using Ubuntu 14.04, just install with `apt-get install keepalived` and replace `/etc/keepalived/keepalived.conf` with the following contents. Adjust it as needed for your environment.

```
vrrp_instance vi1 {
    state MASTER
    interface eth1
    virtual_router_id 51
    priority 101
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass supers3cret
    }
    virtual_ipaddress {
        192.168.5.30/24
    }
}
```

Point your shipper at the shared IP address and now you have nearly-free failover with at-most-once semantics.

Note that this topology will result in event loss if the indexer crashes, but the failure window should be minimal. When performing maintenance, simply stop keepalived on one of the nodes and gracefully stop the indexer. Once you're finished, restart the indexer and keepalived. This should result in zero event loss.

### Active/active

Sometimes log loss is unacceptable, like when dealing with strict auditing requirements. In this case, you would need to stand up multiple receivers, then have your shipper fanout events to them all. Of course, you'll need to perform some time of de-duplication on the log stream. I couldn't find any log indexers that had built-in de-duplication, so I came up with a scalable solution you can place into your logging pipeline. Obviously if your indexer has this feature, you can stop reading and go use that right now. Otherwise, continue on...

![De-duplication with multiple receivers](/images/ha-syslog-dedup.png)

Basically, your shipper will fanout the logs to multiple receivers. These receivers will push directly into a "new events" queue in a RabbitMQ cluster. One or more workers will pull from this queue, and perform the following on each event:

1. Hash the event or grab a unique identifier from the event
2. [Atomically check and set the key](http://redis.io/commands/set) in a shared Redis instance (with an expiration time, to prune events that are outside of your duplication window)
3. If the event has been "seen" before, discard it
4. If the event is new, place it into the "processed" queue in the RabbitMQ cluster

Then the rest of your logging pipeline now can consume the de-duplicated stream of events. You can scale out the de-dup workers as much as needed because they use Redis as a concurrent set.

Some notes about this solution:

- The de-dup worker will prefetch some number of events, process them, then ACK them. If a de-dup worker were to crash, another de-dup worker can pickup the un-acked events.
- If you have a single Redis instance, this can introduce downtime into your de-dup worker pool. Consider using some sort of automatic failover with multiple Redis instances.
- To get better performance out of Redis, you can turn off persistence entirely. This will keep your "seen" event set in-memory. This is only acceptable if you can accept that a crash can result in duplicate events.
- There is a period of time where the de-dup worker could place the event into the "seen" set and crash before it puts the event into the "processed" queue. When another worker picks up the unacked event, it will discard it immediately. To protect against this, you could theoretically have a "discarded" event set to recover missing events.

This hasn't been implemented yet, but it would be easy enough to do in Go, Python or Ruby. If there is enough interest, I would even be willing to take a crack at it. This seems to be the most promising solution for durable, exactly-once log delivery.

### Wrap-up

In this post, I discussed some of the barriers to highly-available logging from network devices that use the Syslog protocol. I presented some solutions, based on which delivery semantics would be desirable to the reader. In my personal opinion, it should never be a requirement for logs to never be lost. Durable logging is a tough path to travel down, one which will introduce a lot of complexity into a system that should otherwise be simple to maintain.
